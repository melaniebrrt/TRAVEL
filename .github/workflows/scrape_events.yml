name: Update events database

on:
  schedule:
    # Tous les 3 jours Ã  06:00 UTC
    # â‰ˆ 10 runs / mois â†’ â‰ˆ 120 requÃªtes / mois
    - cron: "0 6 */3 * *"

  workflow_dispatch: # permet de lancer Ã  la main (sans cron)

jobs:
  scrape:
    runs-on: ubuntu-latest

    env:
      SERPAPI_API_KEY: ${{ secrets.SERPAPI_API_KEY }}

    steps:
      - name: ğŸ“¥ Checkout repository
        uses: actions/checkout@v4

      - name: ğŸ Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      - name: Install dependencies
        run: |
        pip uninstall -y serpapi || true
        pip install -r requirements.txt


      - name: ğŸ§  Run scraper (quota-safe)
        run: |
          python scraping/scrape_events.py

      - name: ğŸ“¤ Commit updated CSV if changed
        run: |
          git config user.name "github-actions"
          git config user.email "actions@github.com"
          git add events_no_london.csv geo_cache.json || true
          git commit -m "auto: update events data" || echo "No changes to commit"
          git push

